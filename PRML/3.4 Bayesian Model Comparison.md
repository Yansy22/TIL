# 📖 베이지안 모델 비교 (Bayesian Model Comparison)

주제: **"어떻게 여러 모델 중 가장 좋은 모델을 공정하게 선택할 것인가?"** 

기존의 다른 모델 비교 방법으로는 정규화, 교차 검증법 등이 있었다.
베이지안 모델 비교는 이 질문에 대해 **'모델 증거(Model Evidence)'** 라는 강력한 척도를 제시한다.

이 방법론의 핵심은 모델의 성능을 **'데이터에 얼마나 잘 맞는가(적합도)'** 로만 판단하는 것이 아니라, **'모델 자체가 얼마나 그럴듯한가(복잡도)'** 를 동시에 고려하여 자동적인 **'오컴의 면도날(Occam's Razor)'** 을 구현한다.

---

### 1. 모델 증거 (Model Evidence): 모델의 최종 점수

모델 비교의 핵심은 각 모델 $M_i$에 대해 **모델 증거 $p(D|M_i)$** 값을 계산하여 비교한다. 이 값이 가장 높은 모델이 최상의 모델이다.

$$
p(D|M_i) = \int p(D|w, M_i) p(w|M_i) dw
$$

이 식은 모델 $M_i$에 속한 **모든 가능한 파라미터 $w$**에 대해 모델의 성능을 **평균**내는 것을 의미한다.

* $p(D|w, M_i)$ : **가능도 (Likelihood)**
    * "특정한 파라미터 $w$가 주어졌을 때, 이 모델이 데이터 $D$를 얼마나 잘 설명하는가?" (즉, **데이터 적합도**)
* $p(w|M_i)$ : **사전 확률 (Prior)**
    * "데이터를 보기 전, 이 파라미터 $w$가 애초에 얼마나 그럴듯한 값인가?" (즉, **파라미터의 타당성**)
* $\int \dots dw$ : **주변화 (Marginalization)**
    * 모델의 성능을 '최고의 파라미터 $w_{MAP}$' 하나로 평가하는 것이 아니라, **모든 $w$에 대해** (적합도 $\times$ 타당성)을 곱한 값을 적분(평균)합니다.

#### 💬 우리의 논의: 왜 이것이 과적합을 막는가? (팀과 선수 비유)

* **복잡한 모델 $M_{complex}$ (예: 10차 다항식):**
    * 이 모델은 훈련 데이터 $D$에 완벽하게 맞는 '스타 선수'($w_{MAP}$)를 찾을 수 있다. $\rightarrow$ $p(D|w_{MAP})$ **(적합도)** 는 매우 높다.
    * 하지만 이 '스타 선수'의 파라미터 값은 (예: +10000, -20000...)처럼 매우 극단적이라 $\rightarrow p(w_{MAP})$ **(타당성)** 은 **거의 0에 가깝다.**
    * 모델 증거(최종 점수)는 이 둘의 곱을 평균낸 값이다. (높은 값 $\times$ 0) + (대부분의 '평범한' 파라미터들의 낮은 적합도) $\approx$ **최종 점수는 낮다.**
* **적절한 모델 $M_{simple}$ (예: 2차 다항식):**
    * 이 모델의 '최고' 파라미터는 $M_{complex}$보다 적합도가 낮을 수 있다.
    * 하지만 이 파라미터는 (예: 0.5, 1.2...)처럼 매우 '그럴듯한' 값이라 $\rightarrow p(w)$ **(타당성)**이 높다.
    * 대부분의 '그럴듯한' 파라미터들이 데이터에 '적당히' 잘 맞다. $\rightarrow$ (적당한 값 $\times$ 높은 값)을 평균내면 $\approx$ **최종 점수는 오히려 더 높다.**

---

### 2. 베이즈 정리와 모델 증거의 관계

그렇다면 모델 증거 $p(D|M_i)$는 모델을 훈련(학습)하는 과정과는 어떤 관계가 있을까?

$$
p(w|D, M_i) = \frac{p(D|w, M_i) p(w|M_i)}{p(D|M_i)}
$$

* $p(w|D, M_i)$: **사후 분포 (Posterior)**. 데이터를 본 후 업데이트된 파라미터 $w$의 분포. **(즉, 모델 훈련의 결과)**
* $p(D|w, M_i) p(w|M_i)$: 가능도 $\times$ 사전 확률.
* $p(D|M_i)$: **모델 증거**.

여기서 모델 증거는 사후 분포의 총합이 1이 되도록 만들어주는 **정규화 상수** 역할을 한다. 즉, 모델을 '훈련'시키는 과정에서 자연스럽게 모델을 '비교'하는 점수가 계산된다.

---

### 3. 오컴의 면도날: 모델 증거의 직관적 이해

위의 적분($\int$)은 계산이 매우 어렵다. 그래서 베이지안 모델 비교가 *왜* 오컴의 면도날처럼 작동하는지 직관적으로 이해하기 위해 다음과 같은 근사식을 사용한다.

$$
\ln p(D) \approx \underbrace{\ln p(D|w_{MAP})}_{\text{1. 적합도 항}} + \underbrace{\ln \left( \frac{\Delta w_{posterior}}{\Delta w_{prior}} \right)}_{\text{2. 복잡도 페널티 항}}
$$

모델의 로그 최종 점수($\ln p(D)$)는 **'최고의 적합도'** 에서 **'복잡도 페널티'** 를 뺀 값과 같다.

* **1. 적합도 항 ($\ln p(D|w_{MAP})$):**
    * 모델이 낼 수 있는 최고의 성능(최적의 $w$ 사용).
    * 이 항만 보면, **복잡한 모델이 항상 승리**한다. (훈련 데이터에 더 잘 맞으니까)

* **2. 복잡도 페널티 항 ($\ln (\frac{\Delta w_{posterior}}{\Delta w_{prior}})$):**
    * 이것이 '오컴 팩터'이다.
    * $\Delta w_{prior}$: 데이터를 보기 전, 파라미터가 존재할 수 있었던 범위. (복잡한 모델일수록 유연하므로 이 범위가 **매우 넓음**)
    * $\Delta w_{posterior}$: 데이터를 본 후, 그 데이터에 맞추기 위해 파라미터가 존재해야 하는 좁은 범위. (과적합 모델일수록 이 범위가 **극도로 좁음**)

#### 💬 우리의 논의: 페널티가 복잡한 모델을 벌하는 방식

* **복잡한 모델 $M_{complex}$:**
    * 페널티 항 $\approx \ln \left( \frac{\text{극도로 좁음}}{\text{매우 넓음}} \right) = \ln(\text{아주 작은 수})$
    * 결과: **매우 큰 음수 페널티
